{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8670edc",
   "metadata": {},
   "source": [
    "# **<h1><center><span style=\"color:#3775a8\"><u>Projet Analyse des données massives </u></span></center></h1>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dbd2d5",
   "metadata": {},
   "source": [
    " #### AYENA Mahougnon Mariel Ulrich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48eb0fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d8c1b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33d884f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ea52109f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer, StopWordsRemover,CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "39202083",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Créer une session Spark\n",
    "spark = SparkSession.builder.appName(\"Lecture JSON\").getOrCreate()\n",
    "\n",
    "# Charger un fichier JSON dans un DataFrame\n",
    "train = spark.read.json(\"./train.json\")\n",
    "test = spark.read.json(\"./test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f513d721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|             message|polarity|\n",
      "+--------------------+--------+\n",
      "|! Comment était l...|       0|\n",
      "|! d'accord! Va-t-...|       0|\n",
      "|!!! Taihen desu n...|       0|\n",
      "|!!!! Auto-dj .. c...|       0|\n",
      "|!!!! Ce n'est que...|       0|\n",
      "+--------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "716c54b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|             message|polarity|\n",
      "+--------------------+--------+\n",
      "|! Et si affamé ma...|       0|\n",
      "|! Identica présen...|       0|\n",
      "|! Je vais enfin m...|       0|\n",
      "|!?!? C'est un jou...|       0|\n",
      "|\"Easy\" qu Le plan...|       0|\n",
      "+--------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f054ac10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train : 128401\n",
      "Total test : 76759\n"
     ]
    }
   ],
   "source": [
    "train_rows=train.count()\n",
    "test_rows=test.count()\n",
    "print(\"Total train :\",train_rows)\n",
    "print(\"Total test :\", test_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "57bb74d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|polarity|\n",
      "+--------+\n",
      "|       0|\n",
      "|       4|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.select(\"polarity\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4aa2166c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|polarity|count|\n",
      "+--------+-----+\n",
      "|       0|61475|\n",
      "|       4|66926|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.groupBy(\"polarity\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eb7673e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test.select(\"polarity\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "78699f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|polarity|count|\n",
      "+--------+-----+\n",
      "|       0|36890|\n",
      "|       4|39869|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test.groupBy(\"polarity\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b691168c",
   "metadata": {},
   "source": [
    "# 2- Prétraitement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aab5975",
   "metadata": {},
   "source": [
    "### 2.1- 1ére méthode d'extraction de caractéristiques :  HashingTF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d695adf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créez l'objet RegexTokenizer pour la tokenization\n",
    "tokenizer = Tokenizer(inputCol=\"message\", outputCol=\"SentimentWords\")\n",
    "# Créez l'objet StopWordsRemover pour supprimer les mots vides\n",
    "stopwords_remover= StopWordsRemover(inputCol=tokenizer.getOutputCol(), outputCol=\"MeaningfulWords\")\n",
    "# Créez l'objet HashingTF pour convertir les mots en vecteurs de compte\n",
    "hashTF = HashingTF(inputCol=stopwords_remover.getOutputCol(), outputCol=\"features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a4726143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+--------------------+--------------------+--------------------+\n",
      "|             message|polarity|      SentimentWords|     MeaningfulWords|            features|\n",
      "+--------------------+--------+--------------------+--------------------+--------------------+\n",
      "|! Comment était l...|       0|[!, comment, étai...|[!, comment, étai...|(262144,[18632,29...|\n",
      "|! d'accord! Va-t-...|       0|[!, d'accord!, va...|[!, d'accord!, va...|(262144,[10096,22...|\n",
      "|!!! Taihen desu n...|       0|[!!!, taihen, des...|[!!!, taihen, des...|(262144,[20025,38...|\n",
      "|!!!! Auto-dj .. c...|       0|[!!!!, auto-dj, ....|[!!!!, auto-dj, ....|(262144,[4231,418...|\n",
      "|!!!! Ce n'est que...|       0|[!!!!, ce, n'est,...|[!!!!, ce, n'est,...|(262144,[18868,29...|\n",
      "+--------------------+--------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Création d'un pipeline\n",
    "from pyspark.ml import Pipeline\n",
    "pipeline = Pipeline(stages=[tokenizer, stopwords_remover ,hashTF])\n",
    "\n",
    "# application du  pipeline aux documents des données d'entrainement \n",
    "pipelineFit = pipeline.fit(train)\n",
    "train_n = pipelineFit.transform(train)\n",
    "# Convertir \"polarity\" en valeurs numériques\n",
    "train_n= train_n.withColumn(\"polarity\",train_n[\"polarity\"].cast(\"int\"))\n",
    "train_n.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1a042247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# application du  pipeline aux documents des données de test.\n",
    "test_n = pipelineFit.transform(test)\n",
    "test_n= test_n.withColumn(\"polarity\",test_n[\"polarity\"].cast(\"int\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d60d14",
   "metadata": {},
   "source": [
    "# 3- Modélisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f68a27",
   "metadata": {},
   "source": [
    "### 3.1- Régression Logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "011560c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrainement du modèle\n",
    "lr = LogisticRegression(labelCol=\"polarity\", featuresCol=\"features\", maxIter=10, regParam=0.01)\n",
    "model_lr = lr.fit(train_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "db543a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- message: string (nullable = true)\n",
      " |-- polarity: integer (nullable = true)\n",
      " |-- SentimentWords: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- MeaningfulWords: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Prediction sur les données test\n",
    "predictions = model_lr.transform(test_n)\n",
    "predictions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7f2cf1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+--------+\n",
      "|     MeaningfulWords|prediction|polarity|\n",
      "+--------------------+----------+--------+\n",
      "|[!, et, si, affam...|       0.0|       0|\n",
      "|[!, identica, pré...|       4.0|       0|\n",
      "|[!, je, vais, enf...|       0.0|       0|\n",
      "|[!?!?, c'est, un,...|       0.0|       0|\n",
      "|[\"easy\", qu, le, ...|       4.0|       0|\n",
      "+--------------------+----------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select(\"MeaningfulWords\", \"prediction\", \"polarity\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0ccd8aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "45c9ee4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7346500084680624\n"
     ]
    }
   ],
   "source": [
    "##Score de la prédiction\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"polarity\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0927716",
   "metadata": {},
   "source": [
    "### 3.2- Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "91d44a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "rf = RandomForestClassifier(labelCol=\"polarity\",featuresCol=\"features\", \\\n",
    "                            numTrees = 100, \\\n",
    "                            maxDepth = 4, \\\n",
    "                            maxBins = 32)\n",
    "model_rf = rf.fit(train_n)\n",
    "predictions_n = model_rf.transform(test_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "d43dca21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5195351685144413\n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"polarity\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions_n)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4349299",
   "metadata": {},
   "source": [
    "### 3.3- Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "7e5a3fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "nb = NaiveBayes(labelCol=\"polarity\", featuresCol=\"features\",smoothing=1)\n",
    "model_nb = nb.fit(train_n)\n",
    "predictions_nn = model_nb.transform(test_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c2bfec46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.378756888443049\n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"polarity\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions_nn)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7a96a3",
   "metadata": {},
   "source": [
    "**Commentaire**:\n",
    "\n",
    "Lors de l'application des trois modèles, nous avons obtenu les résultats suivants : le modèle de régression logistique a une précision de 0.7346 pour prédire les polarités sur les données de test, le Random Forest a une précision de 0.5195, tandis que le modèle Naive Bayes a une précision de 0.3787. Nous avons constaté que parmi ces trois modèles, c'est le modèle de régression logistique qui a obtenu le meilleur score. Par conséquent, nous allons effectuer une validation croisée sur ce modèle en utilisant plusieurs paramètres afin de sélectionner les meilleurs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d90d8e7",
   "metadata": {},
   "source": [
    "### 3.4- Cross-validation avec la régression Logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46f83598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75473885798408\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import  MulticlassClassificationEvaluator\n",
    "\n",
    "lr = LogisticRegression(labelCol=\"polarity\", featuresCol=\"features\")\n",
    "\n",
    "# Création de ParamGrid pour la  Cross Validation\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(lr.regParam, [0.1,0.3])  # régularisation  des paramètres\n",
    "             .addGrid(lr.elasticNetParam, [0.0,0.1])  #  paramètres de Elastic Net  (Ridge = 0)\n",
    "             .addGrid(lr.maxIter, [10,20])  #  Nombre d'itération\n",
    "             .build())\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"polarity\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "# Création de 5-fold CrossValidator\n",
    "cv = CrossValidator(estimator=lr, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n",
    "\n",
    "cvModel = cv.fit(train_n)\n",
    "predictions = cvModel.transform(test_n)\n",
    "\n",
    "# Evaluatin du meilleur modèle\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95a07ed",
   "metadata": {},
   "source": [
    "**Commentaire**\n",
    "\n",
    "Amélioration du score après cross validation sur le modèle de régression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3b510e",
   "metadata": {},
   "source": [
    "# 4- Autres méthodes d'extraction "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ebd948",
   "metadata": {},
   "source": [
    "### 4.1-    2éme méthode d'extraction de caractéristiques :  Term Frequency - Inverse Document Frequency (TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4e7e3a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, Tokenizer,RegexTokenizer, StopWordsRemover,IDF,StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "baaa4513",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"message\", outputCol=\"SentimentWords\")\n",
    "stopwords_remover = StopWordsRemover(inputCol=tokenizer.getOutputCol(), outputCol=\"MeaningfulWords\")\n",
    "hashing_tf = HashingTF(inputCol=stopwords_remover.getOutputCol(), outputCol=\"features\")\n",
    "idf = IDF(inputCol=hashing_tf.getOutputCol(), outputCol=\"idf_features\")\n",
    "#label_string_idx = StringIndexer(inputCol=\"polarity\", outputCol=\"polarity_index\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "48d8685f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pipeline = Pipeline(stages=[tokenizer, stopwords_remover, hashing_tf, idf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "86ec37a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+--------------------+--------------------+--------------------+\n",
      "|             message|polarity|      SentimentWords|     MeaningfulWords|            features|\n",
      "+--------------------+--------+--------------------+--------------------+--------------------+\n",
      "|! Comment était l...|       0|[!, comment, étai...|[!, comment, étai...|(262144,[18632,29...|\n",
      "|! d'accord! Va-t-...|       0|[!, d'accord!, va...|[!, d'accord!, va...|(262144,[10096,22...|\n",
      "|!!! Taihen desu n...|       0|[!!!, taihen, des...|[!!!, taihen, des...|(262144,[20025,38...|\n",
      "|!!!! Auto-dj .. c...|       0|[!!!!, auto-dj, ....|[!!!!, auto-dj, ....|(262144,[4231,418...|\n",
      "|!!!! Ce n'est que...|       0|[!!!!, ce, n'est,...|[!!!!, ce, n'est,...|(262144,[18868,29...|\n",
      "+--------------------+--------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipelineFit2 = pipeline.fit(train)\n",
    "train_n2 = pipelineFit.transform(train)\n",
    "train_n2= train_n2.withColumn(\"polarity\",train_n2[\"polarity\"].cast(\"int\"))\n",
    "train_n2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9211a638",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_n2 = pipelineFit2.transform(test)\n",
    "test_n2= test_n2.withColumn(\"polarity\",test_n2[\"polarity\"].cast(\"int\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779c60f0",
   "metadata": {},
   "source": [
    "### 4.2- Régression Logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9fbea34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model d'entraînement\n",
    "lr = LogisticRegression(labelCol=\"polarity\", featuresCol=\"features\", maxIter=20, regParam=0.3)\n",
    "model_lr = lr.fit(train_n2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bf42e725",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction sur les données test\n",
    "predictions = model_lr.transform(test_n2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a9813326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7546997746192629\n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"polarity\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2fd9b1",
   "metadata": {},
   "source": [
    "### 4.3-   3ème méthode d'extraction de caractéristiques :  CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "00dbc92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créez l'objet RegexTokenizer pour la tokenization\n",
    "#tokenizer =  RegexTokenizer(inputCol=\"message\", outputCol=\"SentimentWords\", pattern=\"\\\\W\")\n",
    "tokenizer =  Tokenizer(inputCol=\"message\", outputCol=\"SentimentWords\")\n",
    "# Créez l'objet StopWordsRemover pour supprimer les mots vides\n",
    "stopwords_remover= StopWordsRemover(inputCol=tokenizer.getOutputCol(), outputCol=\"MeaningfulWords\")\n",
    "# Créez l'objet CountVectorizer pour extraire les vecteurs de compte\n",
    "count_vectorizer = CountVectorizer(inputCol=stopwords_remover.getOutputCol(), outputCol=\"features\")\n",
    "#label_string_idx = StringIndexer(inputCol=\"polarity\", outputCol=\"polarity_index\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8cbc0946",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[tokenizer, stopwords_remover, count_vectorizer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9c423980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+--------------------+--------------------+--------------------+\n",
      "|             message|polarity|      SentimentWords|     MeaningfulWords|            features|\n",
      "+--------------------+--------+--------------------+--------------------+--------------------+\n",
      "|! Comment était l...|       0|[!, comment, étai...|[!, comment, étai...|(101862,[3,21,87,...|\n",
      "|! d'accord! Va-t-...|       0|[!, d'accord!, va...|[!, d'accord!, va...|(101862,[4,6,7,8,...|\n",
      "|!!! Taihen desu n...|       0|[!!!, taihen, des...|[!!!, taihen, des...|(101862,[0,17,43,...|\n",
      "|!!!! Auto-dj .. c...|       0|[!!!!, auto-dj, ....|[!!!!, auto-dj, ....|(101862,[5,8,9,20...|\n",
      "|!!!! Ce n'est que...|       0|[!!!!, ce, n'est,...|[!!!!, ce, n'est,...|(101862,[4,5,6,10...|\n",
      "+--------------------+--------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipelineFit3 = pipeline.fit(train)\n",
    "train_n3 = pipelineFit3.transform(train)\n",
    "train_n3= train_n3.withColumn(\"polarity\",train_n3[\"polarity\"].cast(\"int\"))\n",
    "#train_n3.printSchema()\n",
    "train_n3.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e4722382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+--------------------+--------------------+--------------------+\n",
      "|             message|polarity|      SentimentWords|     MeaningfulWords|            features|\n",
      "+--------------------+--------+--------------------+--------------------+--------------------+\n",
      "|! Et si affamé ma...|       0|[!, et, si, affam...|[!, et, si, affam...|(101862,[0,3,6,7,...|\n",
      "|! Identica présen...|       0|[!, identica, pré...|[!, identica, pré...|(101862,[3,7,21,2...|\n",
      "|! Je vais enfin m...|       0|[!, je, vais, enf...|[!, je, vais, enf...|(101862,[0,1,12,1...|\n",
      "|!?!? C'est un jou...|       0|[!?!?, c'est, un,...|[!?!?, c'est, un,...|(101862,[0,1,2,4,...|\n",
      "|\"Easy\" qu Le plan...|       0|[\"easy\", qu, le, ...|[\"easy\", qu, le, ...|(101862,[2,4,14,1...|\n",
      "+--------------------+--------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#pipelineFit3 = pipeline.fit(test)\n",
    "test_n3 = pipelineFit3.transform(test)\n",
    "test_n3= test_n3.withColumn(\"polarity\",test_n3[\"polarity\"].cast(\"int\"))\n",
    "test_n3.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ef068d",
   "metadata": {},
   "source": [
    "### 4.4-   Régression Logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "144d123f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Model\n",
    "lr = LogisticRegression(labelCol=\"polarity\", featuresCol=\"features\", maxIter=20, regParam=0.3)\n",
    "model_lr = lr.fit(train_n3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d994e82c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Prediction\n",
    "predictions = model_lr.transform(test_n3)\n",
    "#predictions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0dd789ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+--------+\n",
      "|      SentimentWords|prediction|polarity|\n",
      "+--------------------+----------+--------+\n",
      "|[!, et, si, affam...|       0.0|       0|\n",
      "|[!, identica, pré...|       4.0|       0|\n",
      "|[!, je, vais, enf...|       0.0|       0|\n",
      "|[!?!?, c'est, un,...|       0.0|       0|\n",
      "|[\"easy\", qu, le, ...|       0.0|       0|\n",
      "+--------------------+----------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction_final = predictions.select(\"SentimentWords\", \"prediction\", \"polarity\")\n",
    "prediction_final.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "96c021f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7611615576023658\n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"polarity\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf19313",
   "metadata": {},
   "source": [
    "**Commentaire**\n",
    "\n",
    "En utilisant la méthode d'extraction de caractéristiques **CountVectorizer** et la régression logistique avec les meilleurs paramètres, nous avons un score de 76,11% . Ce qui est suppérieur à tous les autres scores trouvés.Donc nous allons garder cette technique d'extration pour faire les prédiction sur le fichier **noclass**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed74166d",
   "metadata": {},
   "source": [
    "### 4-5  Prédiction sur le fichier noclass.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6431ad",
   "metadata": {},
   "source": [
    "Pour cette partie nous allons faire les prédictions avec le meilleur modèle. C'est à dire le modèle le plus performant en terme de score. Dans notre c'est le modèle de régression logistique avec les bons paramètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "585868d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Lecture du fichier\n",
    "noclass = spark.read.json(\"./noclass.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "88c2977b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|             message|\n",
      "+--------------------+\n",
      "|\"Dans ganga\" Ne v...|\n",
      "|\"Dieu elton\" vous...|\n",
      "|\"I was up up the ...|\n",
      "|\"Quasi\" toute la ...|\n",
      "|# $ & Amp; * # vi...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "noclass.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7b26621b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|             message|      SentimentWords|     MeaningfulWords|            features|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|\"Dans ganga\" Ne v...|[\"dans, ganga\", n...|[\"dans, ganga\", n...|(101862,[1,3,4,6,...|\n",
      "|\"Dieu elton\" vous...|[\"dieu, elton\", v...|[\"dieu, elton\", v...|(101862,[0,1,5,6,...|\n",
      "|\"I was up up the ...|[\"i, was, up, up,...|[\"i, half, night,...|(101862,[1,5,6,17...|\n",
      "|\"Quasi\" toute la ...|[\"quasi\", toute, ...|[\"quasi\", toute, ...|(101862,[1,3,7,14...|\n",
      "|# $ & Amp; * # vi...|[#, $, &, amp;, *...|[#, $, &, amp;, *...|(101862,[0,6,7,12...|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "noclass_n = pipelineFit3.transform(noclass)\n",
    "noclass_n.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149ed361",
   "metadata": {},
   "source": [
    "#####  Apllication de la régression Logistique au données du fichier noclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5b87b8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|             message|      SentimentWords|     MeaningfulWords|            features|       rawPrediction|         probability|prediction|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|\"Dans ganga\" Ne v...|[\"dans, ganga\", n...|[\"dans, ganga\", n...|(101862,[1,3,4,6,...|[6.65713799494093...|[0.50338760506601...|       0.0|\n",
      "|\"Dieu elton\" vous...|[\"dieu, elton\", v...|[\"dieu, elton\", v...|(101862,[0,1,5,6,...|[7.78662181371817...|[0.90656960881930...|       0.0|\n",
      "|\"I was up up the ...|[\"i, was, up, up,...|[\"i, half, night,...|(101862,[1,5,6,17...|[6.97102532189767...|[0.65505020154945...|       0.0|\n",
      "|\"Quasi\" toute la ...|[\"quasi\", toute, ...|[\"quasi\", toute, ...|(101862,[1,3,7,14...|[6.84104638127328...|[0.59419197081360...|       0.0|\n",
      "|# $ & Amp; * # vi...|[#, $, &, amp;, *...|[#, $, &, amp;, *...|(101862,[0,6,7,12...|[7.38597951366197...|[0.81324328466584...|       0.0|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Prediction\n",
    "predictions_noclass = model_lr.transform(noclass_n)\n",
    "predictions_noclass.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d2566c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|             message|prediction|\n",
      "+--------------------+----------+\n",
      "|\"Dans ganga\" Ne v...|       0.0|\n",
      "|\"Dieu elton\" vous...|       0.0|\n",
      "|\"I was up up the ...|       0.0|\n",
      "|\"Quasi\" toute la ...|       0.0|\n",
      "|# $ & Amp; * # vi...|       0.0|\n",
      "+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction_final_noclass = predictions_noclass.select(\"message\", \"prediction\")\n",
    "prediction_final_noclass.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3314fcb",
   "metadata": {},
   "source": [
    "### 4-6 Exportation du fichier Noclass avec les prédiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e3770a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fichier des prédictions\n",
    "predictions = prediction_final_noclass.withColumn(\"prediction\", col(\"prediction\").cast(\"integer\"))\n",
    "predictions_json = predictions.select('message','prediction').coalesce(1)\n",
    "predictions_json.write.json(\"./predictions.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2d6795",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
